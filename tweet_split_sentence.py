# -*- coding: utf-8 -*-
"""Tweet_split_sentence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o46h_8QsAU7QxWAYezWd-9_RQAutaB2Q
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import nltk
from nltk.tokenize import sent_tokenize

# Specify the path to your Excel file in Google Drive
Combine_path = '/content/drive/MyDrive/Food Image Analysis/Analysis/Image/mc_kfc_tweet_image_measure.csv'


# Read the Excel file into a DataFrame
Image_df = pd.read_csv(Combine_path)

Image_df

# Create a run number column
Image_df['ImageC_id'] = range(1, len(Image_df) + 1)

# Set 'run_number' as the index
Image_df = Image_df.set_index('ImageC_id')

Image_df

# Ensure NLTK resources are downloaded
nltk.download('punkt')
nltk.download('punkt_tab')

# Function to split sentences
def split_sentences(text):
    return sent_tokenize(text)

# Apply the function to the DataFrame
Image_df['sentences'] = Image_df['Tweet'].apply(split_sentences)

Image_df

# Explode the list of sentences into separate rows
Sentence_df = Image_df.explode('sentences')

Sentence_df

#Mc_df_sentences = Mc_df_unique_sentences[['id', 'Tweet', 'sentences']]

# filter the rows that contain only url
substring = 'http'
filter = Sentence_df['sentences'].str.startswith(substring)
Sentence_df_filtered = Sentence_df[~filter]

#filter = Mc_df_sentences['sentences'].str.startswith(substring)
Sentence_df_filtered

Sentence_df_filtered.to_csv('/content/drive/MyDrive/Food Image Analysis/Analysis/Text/mc_kfc_before_speechAct_coded.csv')

Mc_df_sentences_filtered['speechAct'] = pd.Series(dtype='int')

Mc_df_sentences_filtered['speechAct_Why'] = None

Mc_df_sentences_filtered.to_csv('/content/drive/MyDrive/Food Image Analysis/VGG16/McDonalds(downloadURL)/McDonald__tweet_sentence_19_24_6.xlsx')